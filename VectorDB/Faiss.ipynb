{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71adbc14",
   "metadata": {},
   "source": [
    "Facebook AI similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31253d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59bed5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/vectordb/lib/python3.10/site-packages (from requests) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87405ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"Journal on Vector Databases\n",
    "Abstract\n",
    "\n",
    "With the rapid rise of artificial intelligence (AI) and large language models (LLMs), the need for efficient storage and retrieval of high-dimensional vector data has emerged as a critical requirement. Vector databases (VectorDBs) provide the infrastructure to perform similarity search at scale, enabling applications such as semantic search, recommendation systems, anomaly detection, and retrieval-augmented generation (RAG). This paper discusses the architecture, applications, advantages, and challenges of vector databases.\n",
    "\n",
    "Introduction\n",
    "\n",
    "Traditional databases are designed to handle structured, relational, or document-based data. However, modern AI applications generate embeddings—dense numerical vectors—that capture semantic meaning. Searching in this high-dimensional space requires specialized data structures and algorithms. Vector databases bridge this gap, enabling nearest-neighbor search across billions of vectors efficiently.\n",
    "\n",
    "Core Concepts\n",
    "\n",
    "Vector Embeddings: Numerical representations of unstructured data (e.g., sentences, images) in a continuous vector space.\n",
    "\n",
    "Similarity Metrics: Methods such as cosine similarity, Euclidean distance, or dot product to measure closeness of vectors.\n",
    "\n",
    "Indexing Techniques: Structures like HNSW (Hierarchical Navigable Small World), IVF (Inverted File Index), and PQ (Product Quantization) optimize search performance.\n",
    "\n",
    "Approximate Nearest Neighbor (ANN) Search: Balances speed and accuracy for scalable similarity queries.\n",
    "\n",
    "Architecture of a Vector Database\n",
    "\n",
    "A VectorDB typically includes:\n",
    "\n",
    "Storage Layer: Stores embeddings along with metadata.\n",
    "\n",
    "Index Layer: Organizes embeddings into searchable structures.\n",
    "\n",
    "Query Engine: Executes similarity searches.\n",
    "\n",
    "Integration Layer: Provides APIs for AI/ML pipelines, often REST or gRPC endpoints.\n",
    "\n",
    "Applications\n",
    "\n",
    "Semantic Search – retrieving relevant documents or passages based on meaning rather than keywords.\n",
    "\n",
    "Recommendation Systems – finding similar products, users, or media.\n",
    "\n",
    "Fraud and Anomaly Detection – identifying outliers in high-dimensional financial or cybersecurity data.\n",
    "\n",
    "Multimodal AI – searching across different media types (text-to-image retrieval).\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) – powering LLMs with external knowledge bases.\n",
    "\n",
    "Popular Vector Databases\n",
    "\n",
    "Pinecone – managed vector DB service with strong cloud integration.\n",
    "\n",
    "Weaviate – open-source, schema-aware vector database.\n",
    "\n",
    "Milvus – high-performance open-source VectorDB for large-scale similarity search.\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) – a library for efficient ANN search (often embedded in VectorDBs).\n",
    "\n",
    "Qdrant – open-source vector search engine optimized for production.\n",
    "\n",
    "Challenges\n",
    "\n",
    "Scalability: Managing billions of vectors with low latency.\n",
    "\n",
    "Hybrid Search: Combining vector similarity with traditional keyword or filter-based search.\n",
    "\n",
    "Data Freshness: Updating embeddings dynamically as content evolves.\n",
    "\n",
    "Cost Efficiency: Storing and querying large volumes of embeddings.\n",
    "\n",
    "Future Directions\n",
    "\n",
    "The adoption of VectorDBs will accelerate as LLMs and generative AI scale. Integration with relational databases, graph databases, and cloud-native architectures will shape the next generation of hybrid intelligent data platforms.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Vector databases represent a paradigm shift in data storage and retrieval. They enable machines to understand and search based on meaning rather than syntax, making them foundational for AI-driven applications. Their role will continue to expand across industries as data becomes increasingly unstructured and AI systems demand more sophisticated retrieval mechanisms.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87260ea",
   "metadata": {},
   "source": [
    "Convert data into small chunk to make it readable in better way\n",
    "perform data cleaning based on NLP principles.\n",
    "mostly  steps are required 1. data collection, data reading, data cleaning (make data chunks with overlap data for better integration), embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8399c",
   "metadata": {},
   "source": [
    "#Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732ea717",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_data = data.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea546cf1",
   "metadata": {},
   "source": [
    "Use 300–500 tokens per chunk for general-purpose search.\n",
    "✅ Increase to 800–1200 tokens if your model & use case need more context (e.g., RAG).\n",
    "✅ Keep 10–20% overlap between chunks. if chunk size is 1000 then overlap should be between 100-200\n",
    "✅ Align chunks to sentence/paragraph boundaries where possible.\n",
    "✅ Pre-process text (remove boilerplate, tables, repeated headers).\n",
    "✅ Store metadata (e.g., section, page, source) with each chunk in the VectorDB → helps in filtering later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b821314",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 800 # chunk size\n",
    "overlap = 100 # overlap is needed between chunks to make relation between data chunks\n",
    "chunks = []\n",
    "i=0\n",
    "while i < len(Clean_data):\n",
    "    piece = Clean_data[i:i+max_char]\n",
    "    chunks.append(piece)\n",
    "    i = i+max_char - overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edfe8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29634516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Journal on Vector Databases\\nAbstract\\n\\nWith the rapid rise of artificial intelligence (AI) and large language models (LLMs), the need for efficient storage and retrieval of high-dimensional vector data has emerged as a critical requirement. Vector databases (VectorDBs) provide the infrastructure to perform similarity search at scale, enabling applications such as semantic search, recommendation systems, anomaly detection, and retrieval-augmented generation (RAG). This paper discusses the architecture, applications, advantages, and challenges of vector databases.\\n\\nIntroduction\\n\\nTraditional databases are designed to handle structured, relational, or document-based data. However, modern AI applications generate embeddings—dense numerical vectors—that capture semantic meaning. Searching in this',\n",
       " 'cations generate embeddings—dense numerical vectors—that capture semantic meaning. Searching in this high-dimensional space requires specialized data structures and algorithms. Vector databases bridge this gap, enabling nearest-neighbor search across billions of vectors efficiently.\\n\\nCore Concepts\\n\\nVector Embeddings: Numerical representations of unstructured data (e.g., sentences, images) in a continuous vector space.\\n\\nSimilarity Metrics: Methods such as cosine similarity, Euclidean distance, or dot product to measure closeness of vectors.\\n\\nIndexing Techniques: Structures like HNSW (Hierarchical Navigable Small World), IVF (Inverted File Index), and PQ (Product Quantization) optimize search performance.\\n\\nApproximate Nearest Neighbor (ANN) Search: Balances speed and accuracy for scalable si',\n",
       " 'performance.\\n\\nApproximate Nearest Neighbor (ANN) Search: Balances speed and accuracy for scalable similarity queries.\\n\\nArchitecture of a Vector Database\\n\\nA VectorDB typically includes:\\n\\nStorage Layer: Stores embeddings along with metadata.\\n\\nIndex Layer: Organizes embeddings into searchable structures.\\n\\nQuery Engine: Executes similarity searches.\\n\\nIntegration Layer: Provides APIs for AI/ML pipelines, often REST or gRPC endpoints.\\n\\nApplications\\n\\nSemantic Search – retrieving relevant documents or passages based on meaning rather than keywords.\\n\\nRecommendation Systems – finding similar products, users, or media.\\n\\nFraud and Anomaly Detection – identifying outliers in high-dimensional financial or cybersecurity data.\\n\\nMultimodal AI – searching across different media types (text-to-image retrieva',\n",
       " ' cybersecurity data.\\n\\nMultimodal AI – searching across different media types (text-to-image retrieval).\\n\\nRetrieval-Augmented Generation (RAG) – powering LLMs with external knowledge bases.\\n\\nPopular Vector Databases\\n\\nPinecone – managed vector DB service with strong cloud integration.\\n\\nWeaviate – open-source, schema-aware vector database.\\n\\nMilvus – high-performance open-source VectorDB for large-scale similarity search.\\n\\nFAISS (Facebook AI Similarity Search) – a library for efficient ANN search (often embedded in VectorDBs).\\n\\nQdrant – open-source vector search engine optimized for production.\\n\\nChallenges\\n\\nScalability: Managing billions of vectors with low latency.\\n\\nHybrid Search: Combining vector similarity with traditional keyword or filter-based search.\\n\\nData Freshness: Updating embeddings',\n",
       " 'tor similarity with traditional keyword or filter-based search.\\n\\nData Freshness: Updating embeddings dynamically as content evolves.\\n\\nCost Efficiency: Storing and querying large volumes of embeddings.\\n\\nFuture Directions\\n\\nThe adoption of VectorDBs will accelerate as LLMs and generative AI scale. Integration with relational databases, graph databases, and cloud-native architectures will shape the next generation of hybrid intelligent data platforms.\\n\\nConclusion\\n\\nVector databases represent a paradigm shift in data storage and retrieval. They enable machines to understand and search based on meaning rather than syntax, making them foundational for AI-driven applications. Their role will continue to expand across industries as data becomes increasingly unstructured and AI systems demand more so',\n",
       " ' to expand across industries as data becomes increasingly unstructured and AI systems demand more sophisticated retrieval mechanisms.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72c86f",
   "metadata": {},
   "source": [
    "Embedding: Convert data into numerical format using some model or API, this model must relate to  text Embedding & similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aafd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-6fd0de29827ed6295aaa48cebc00e9705077ac2fcec039476ef67c19cf13e07a\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-small\" #Open-AI based embedding model, supports multilingual.\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "text = \"The weather is sunny today.\"\n",
    "\n",
    "embedding = generate_embeddings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be68ee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01709348  0.03181893  0.03002567 ...  0.02860025  0.01844992\n",
      "  0.00995491]\n",
      "[-0.00992389  0.02803624  0.05719573 ...  0.01869083 -0.00962623\n",
      "  0.01687117]\n",
      "[-0.02161345  0.04889561  0.03228603 ...  0.02150847  0.01083588\n",
      " -0.00042282]\n",
      "[-8.1308280e-05  3.7904516e-02  5.5489090e-02 ...  1.7649697e-02\n",
      "  1.3715965e-02  1.1892379e-02]\n",
      "[-0.01607724  0.02467457  0.02392202 ...  0.03739953  0.01955494\n",
      "  0.00642519]\n",
      "[-0.00881631 -0.00226156  0.05537876 ... -0.00156267 -0.00101808\n",
      "  0.02672122]\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    embedding = generate_embeddings(i)\n",
    "    print(embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13099957",
   "metadata": {},
   "source": [
    "Store this embedded data into the vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54cfaa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk1 embedding:[-0.01709348  0.03181893  0.03002567 ...  0.02860025  0.01844992\n",
      "  0.00995491]\n",
      "chunk2 embedding:[-0.0099126   0.02803608  0.05728526 ...  0.01870195 -0.0096374\n",
      "  0.0168823 ]\n",
      "chunk3 embedding:[-0.02167191  0.04886963  0.03226888 ...  0.02149704  0.01100499\n",
      " -0.00031895]\n",
      "chunk4 embedding:[-8.1308280e-05  3.7904516e-02  5.5489090e-02 ...  1.7649697e-02\n",
      "  1.3715965e-02  1.1892379e-02]\n",
      "chunk5 embedding:[-0.01605848  0.02470361  0.02390524 ...  0.03743178  0.01958268\n",
      "  0.00640971]\n",
      "chunk6 embedding:[-0.00885155 -0.00227339  0.05537213 ... -0.00149971 -0.00100888\n",
      "  0.02671802]\n"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "metadata = []\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    vec = generate_embeddings(chunk)\n",
    "    emb_list.append(vec.astype(\"float32\"))\n",
    "    metadata.append({\"id\": idx, \"text\": chunk})\n",
    "    print(f\"chunk{idx+1} embedding:{vec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7680cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01709348,  0.03181893,  0.03002567, ...,  0.02860025,\n",
       "         0.01844992,  0.00995491], shape=(1536,), dtype=float32),\n",
       " array([-0.0099126 ,  0.02803608,  0.05728526, ...,  0.01870195,\n",
       "        -0.0096374 ,  0.0168823 ], shape=(1536,), dtype=float32),\n",
       " array([-0.02167191,  0.04886963,  0.03226888, ...,  0.02149704,\n",
       "         0.01100499, -0.00031895], shape=(1536,), dtype=float32),\n",
       " array([-8.1308281e-05,  3.7904516e-02,  5.5489089e-02, ...,\n",
       "         1.7649697e-02,  1.3715965e-02,  1.1892379e-02],\n",
       "       shape=(1536,), dtype=float32),\n",
       " array([-0.01605848,  0.02470361,  0.02390524, ...,  0.03743178,\n",
       "         0.01958268,  0.00640971], shape=(1536,), dtype=float32),\n",
       " array([-0.00885155, -0.00227339,  0.05537213, ..., -0.00149971,\n",
       "        -0.00100888,  0.02671802], shape=(1536,), dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b942047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'text': 'Journal on Vector Databases\\nAbstract\\n\\nWith the rapid rise of artificial intelligence (AI) and large language models (LLMs), the need for efficient storage and retrieval of high-dimensional vector data has emerged as a critical requirement. Vector databases (VectorDBs) provide the infrastructure to perform similarity search at scale, enabling applications such as semantic search, recommendation systems, anomaly detection, and retrieval-augmented generation (RAG). This paper discusses the architecture, applications, advantages, and challenges of vector databases.\\n\\nIntroduction\\n\\nTraditional databases are designed to handle structured, relational, or document-based data. However, modern AI applications generate embeddings—dense numerical vectors—that capture semantic meaning. Searching in this'},\n",
       " {'id': 1,\n",
       "  'text': 'cations generate embeddings—dense numerical vectors—that capture semantic meaning. Searching in this high-dimensional space requires specialized data structures and algorithms. Vector databases bridge this gap, enabling nearest-neighbor search across billions of vectors efficiently.\\n\\nCore Concepts\\n\\nVector Embeddings: Numerical representations of unstructured data (e.g., sentences, images) in a continuous vector space.\\n\\nSimilarity Metrics: Methods such as cosine similarity, Euclidean distance, or dot product to measure closeness of vectors.\\n\\nIndexing Techniques: Structures like HNSW (Hierarchical Navigable Small World), IVF (Inverted File Index), and PQ (Product Quantization) optimize search performance.\\n\\nApproximate Nearest Neighbor (ANN) Search: Balances speed and accuracy for scalable si'},\n",
       " {'id': 2,\n",
       "  'text': 'performance.\\n\\nApproximate Nearest Neighbor (ANN) Search: Balances speed and accuracy for scalable similarity queries.\\n\\nArchitecture of a Vector Database\\n\\nA VectorDB typically includes:\\n\\nStorage Layer: Stores embeddings along with metadata.\\n\\nIndex Layer: Organizes embeddings into searchable structures.\\n\\nQuery Engine: Executes similarity searches.\\n\\nIntegration Layer: Provides APIs for AI/ML pipelines, often REST or gRPC endpoints.\\n\\nApplications\\n\\nSemantic Search – retrieving relevant documents or passages based on meaning rather than keywords.\\n\\nRecommendation Systems – finding similar products, users, or media.\\n\\nFraud and Anomaly Detection – identifying outliers in high-dimensional financial or cybersecurity data.\\n\\nMultimodal AI – searching across different media types (text-to-image retrieva'},\n",
       " {'id': 3,\n",
       "  'text': ' cybersecurity data.\\n\\nMultimodal AI – searching across different media types (text-to-image retrieval).\\n\\nRetrieval-Augmented Generation (RAG) – powering LLMs with external knowledge bases.\\n\\nPopular Vector Databases\\n\\nPinecone – managed vector DB service with strong cloud integration.\\n\\nWeaviate – open-source, schema-aware vector database.\\n\\nMilvus – high-performance open-source VectorDB for large-scale similarity search.\\n\\nFAISS (Facebook AI Similarity Search) – a library for efficient ANN search (often embedded in VectorDBs).\\n\\nQdrant – open-source vector search engine optimized for production.\\n\\nChallenges\\n\\nScalability: Managing billions of vectors with low latency.\\n\\nHybrid Search: Combining vector similarity with traditional keyword or filter-based search.\\n\\nData Freshness: Updating embeddings'},\n",
       " {'id': 4,\n",
       "  'text': 'tor similarity with traditional keyword or filter-based search.\\n\\nData Freshness: Updating embeddings dynamically as content evolves.\\n\\nCost Efficiency: Storing and querying large volumes of embeddings.\\n\\nFuture Directions\\n\\nThe adoption of VectorDBs will accelerate as LLMs and generative AI scale. Integration with relational databases, graph databases, and cloud-native architectures will shape the next generation of hybrid intelligent data platforms.\\n\\nConclusion\\n\\nVector databases represent a paradigm shift in data storage and retrieval. They enable machines to understand and search based on meaning rather than syntax, making them foundational for AI-driven applications. Their role will continue to expand across industries as data becomes increasingly unstructured and AI systems demand more so'},\n",
       " {'id': 5,\n",
       "  'text': ' to expand across industries as data becomes increasingly unstructured and AI systems demand more sophisticated retrieval mechanisms.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c7dc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = np.vstack(emb_list) #Numpy compatible data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a1367",
   "metadata": {},
   "source": [
    "Normalize the data to make it importable into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7c916d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36aff024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss.normalize_L2(xb)\n",
    "d = xb.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(xb) # DataStorage command, this data is currently stored in the memory and not in a real real phyzical files/storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c2be3",
   "metadata": {},
   "source": [
    "Data Storage in physical files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7def4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = \"index_vectordb.faiss\" # store index to physical file with this name\n",
    "meta_path = \"meta_vectordb.json\" # store meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d0c7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5036f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a0d5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta_path, \"w\") as f:\n",
    "    for item in metadata:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8265d",
   "metadata": {},
   "source": [
    "Search Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acbd8f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.4657818 , 0.46344537, 0.45117822, 0.44971085, 0.37138897]],\n",
       "       dtype=float32),\n",
       " array([[2, 0, 3, 4, 1]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is vectordb ?\"\n",
    "#convert query to embedding\n",
    "q = generate_embeddings(query).astype(\"float32\").reshape(1, -1)\n",
    "faiss.normalize_L2(q) # normalize the query to convert to reabable format for vectordb\n",
    "index.search(q, 5) # which search result is best fit to my query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9de87",
   "metadata": {},
   "source": [
    "(array([[0.4657818 , 0.46344537, 0.45117822, 0.44971085, 0.37138897]],\n",
    "       dtype=float32),\n",
    " array([[2, 0, 3, 4, 1]]))\n",
    "\n",
    " these are the python similarity score with respect to my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9ce3881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  6.,  7.,  9., 10.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test and checking how normalize regularisation works, normalization_L2 is a norm regularization technique and will always be lesser than 1.\n",
    "test = np.array([[5,6,7,9,10]], dtype = np.float32)\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff1adb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(17.058722)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(test) # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5dda1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(test) # backend math is cosine similarity, working with indexflatIP function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bb4d13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(1.0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0d8cf",
   "metadata": {},
   "source": [
    "Test done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466482b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
